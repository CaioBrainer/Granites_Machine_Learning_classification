{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c93e251",
   "metadata": {},
   "source": [
    "# <center> GRANITES CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22961b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#utilitários\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "#Pré processamento\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "#Modelos\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "#SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#Avaliadores\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.utils import compute_sample_weight\n",
    "\n",
    "#salvar e carregar modelos treinados\n",
    "import joblib\n",
    "\n",
    "#filtrando alertas\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "xgb.set_config(verbosity=0)\n",
    "\n",
    "#parâmetros para o matplotlib\n",
    "plt.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046ea092",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funções usadas no notebook\n",
    "\n",
    "def treino_de_classificadores(classificadores, X_treino, y_treino, pesos=None):\n",
    "    for classificador in classificadores:\n",
    "        classificador.fit(X_treino, np.ravel(y_treino), sample_weight=pesos)\n",
    "        y_previsao = cross_val_predict(classificador, X_treino, y_treino, cv=10)\n",
    "        precisao = precision_score(y_treino, y_previsao, average = 'macro')\n",
    "        revocacao = recall_score(y_treino, y_previsao, average = 'macro')\n",
    "        pontuacao_f1 = f1_score(y_treino, y_previsao, average = 'macro')\n",
    "        print(classificador.__class__.__name__)\n",
    "        print(f'precisão:{precisao}, revocação:{revocacao}, F1 score: {pontuacao_f1}')\n",
    "        \n",
    "def teste_de_modelos(modelos, X_teste, y_teste):\n",
    "    for modelo in modelos:\n",
    "        previsoes_teste = modelo.predict(X_teste)\n",
    "        print(modelo.__class__.__name__)\n",
    "        print(classification_report(y_teste, previsoes_teste))\n",
    "        print('_________________________________________________________________________________________________________')\n",
    "        \n",
    "def metricas_score(modelos, X_teste, y_teste, imb_treatment='No_treatment'): #imb_treatment\n",
    "    metricas_modelo = {}\n",
    "    for indice, modelo in enumerate(modelos):\n",
    "        nome = modelo.__class__.__name__\n",
    "        previsao = modelo.predict(X_teste)\n",
    "        f1 = f1_score(y_teste, previsao, average='macro')\n",
    "        precisao = precision_score(y_teste, previsao, average='macro')\n",
    "        acuracia = accuracy_score(y_teste, previsao)\n",
    "        imb_treatment = imb_treatment\n",
    "\n",
    "        metricas_modelo[indice] = nome, f1, acuracia, precisao, imb_treatment\n",
    "        \n",
    "        \n",
    "    return pd.DataFrame.from_dict(metricas_modelo, orient='index', columns=['Modelo', 'F1', 'Acurácia', 'Precisão', 'imb_treatment'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61a55182",
   "metadata": {},
   "source": [
    "## <center> LOADING AND PREPARING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3449f90d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Carregando o database tratado\n",
    "database = pd.read_csv('dataset/db_bonin(2020)_update.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443120b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separando variáveis preditoras e variável alvo\n",
    "\n",
    "database_preditores = database[['SiO2', 'TiO2', 'Al2O3','FeOt', 'MnO', 'MgO', 'CaO', \n",
    "                                'K2O', 'Na2O']]\n",
    "\n",
    "database_alvo = database[['Group']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "092131e3",
   "metadata": {},
   "source": [
    "## <center> EXPLORATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6621231b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(15,15))\n",
    "plt.subplots_adjust(wspace=0.40, hspace=0.1)\n",
    "\n",
    "contagem = 0\n",
    "for i in range(0,2):\n",
    "    for j in range(0,3):\n",
    "        sns.boxplot(ax=axes[i, j], data=database_preditores, x=database_alvo['Group'], y=database_preditores.columns[contagem], palette=\"pastel\")\n",
    "        contagem += 1\n",
    "plt.setp(axes, xticks=[], xlabel=None);\n",
    "\n",
    "for i in range(2,3):\n",
    "    for j in range(0,3):\n",
    "        sns.boxplot(ax=axes[i, j], data=database_preditores, x=database_alvo['Group'], y=database_preditores.columns[contagem], palette=\"pastel\")\n",
    "        contagem += 1\n",
    "        \n",
    "for i in range(0,3):\n",
    "    axes[2,i].set_xticklabels(axes[2,i].get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "plt.setp(axes, xlabel=None);\n",
    "plt.savefig('boxplot.jpeg')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63b3890c",
   "metadata": {},
   "source": [
    "# <center> PRE PROCESSING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ce2c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizando um amostragem estratificada\n",
    "X_train, X_test, y_train, y_test = train_test_split(database_preditores, database_alvo, test_size=0.30, stratify=database_alvo, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "encoder = LabelEncoder()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "y_train_encoded = encoder.fit_transform(y_train)\n",
    "\n",
    "#Preparing SMOTE train\n",
    "smote = SMOTE()\n",
    "scaler_smt = StandardScaler()\n",
    "encoder_smt = LabelEncoder()\n",
    "\n",
    "X_train_smt, y_train_smt = smote.fit_resample(X_train, y_train)\n",
    "X_train_smt_scaled = scaler_smt.fit_transform(X_train_smt)\n",
    "y_train_smt_encoded = encoder_smt.fit_transform(y_train_smt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d26a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing SMOTE train\n",
    "smote = SMOTE()\n",
    "scaler_smt = StandardScaler()\n",
    "encoder_smt = LabelEncoder()\n",
    "\n",
    "X_train_smt, y_train_smt = smote.fit_resample(X_train, y_train)\n",
    "X_train_smt_scaled = scaler_smt.fit_transform(X_train_smt)\n",
    "y_train_smt_encoded = encoder_smt.fit_transform(y_train_smt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f7b58d0",
   "metadata": {},
   "source": [
    "# <center> TRAINING BASE MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363d1be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "lda_clf = LinearDiscriminantAnalysis(n_components=3)\n",
    "lda_model = lda_clf.fit(X_train_scaled, y_train_encoded).transform(X_train_scaled)\n",
    "\n",
    "models_base = [lda_clf]\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "y_test_encoded = encoder.transform(y_test)\n",
    "\n",
    "\n",
    "metricas_modelos = metricas_score(models_base, X_test_scaled, y_test_encoded, 'lda')\n",
    "metricas_modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295beb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEGENDA = encoder.classes_\n",
    "plt.subplots(figsize=(10,10))\n",
    "sns.scatterplot(x=lda_model[:,0], y=lda_model[:,1], hue=y_train_encoded, palette=\"deep\", alpha=0.7)\n",
    "plt.legend(LEGENDA, loc='upper left')\n",
    "sns.set_style(\"whitegrid\");\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b2bb415",
   "metadata": {},
   "source": [
    "# <center> TRAINING MODELS AND REALIZING HYPERPARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99552d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM FOREST's\n",
    "\n",
    "param_grid_forest = [{'bootstrap': [False],\n",
    "                      'criterion': ['entropy'],\n",
    "                      'n_estimators': [50, 100], \n",
    "                      'max_features': [3, 4],\n",
    "                      'max_depth': [None, 5, 8, 10]}]\n",
    "\n",
    "grid_search_forest = GridSearchCV(rnd_clf, param_grid_forest, cv = 5, scoring = 'accuracy', return_train_score = True, n_jobs=-1)\n",
    "grid_search_forest.fit(X_train_scaled, np.ravel(y_train))\n",
    "\n",
    "\n",
    "\n",
    "#ADABOOSTING\n",
    "\n",
    "param_grid_ADA = [{'n_estimators': [100],\n",
    "                   'algorithm': ['SAMME'],\n",
    "                   'learning_rate': [0.70, 0.75, 0,80],\n",
    "                  }]\n",
    "\n",
    "grid_search_ada = GridSearchCV(AdaBoostClassifier(DecisionTreeClassifier()), param_grid_ADA, \n",
    "                               cv = 5, scoring = 'accuracy', return_train_score = True, verbose = 2, n_jobs=-1) \n",
    "grid_search_ada.fit(X_train_scaled, np.ravel(y_train))\n",
    "\n",
    "#XGBoost\n",
    "\n",
    "..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f338762b",
   "metadata": {},
   "source": [
    "# <center> TRAINING AND TESTING THE BEST MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a8ef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Post GridSearCV models\n",
    "\n",
    "best_rnd_clf = RandomForestClassifier(bootstrap=False, max_features=3, criterion='entropy', n_estimators=100, random_state=42)\n",
    "xgb_best = xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=0.3,\n",
    "               colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
    "               eval_metric='mlogloss', gamma=0, gpu_id=-1, importance_type=None,\n",
    "               interaction_constraints='', learning_rate=0.2, max_delta_step=0,\n",
    "               max_depth=6, min_child_weight=1,\n",
    "               monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
    "               num_parallel_tree=5, objective='multi:softprob', predictor='auto',\n",
    "               random_state=42, reg_alpha=0, reg_lambda=1, scale_pos_weight=1.5,\n",
    "               subsample=0.9, tree_method='exact', validate_parameters=1,\n",
    "               verbosity=None)\n",
    "\n",
    "best_ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=10) ,algorithm='SAMME', n_estimators=100, learning_rate=0.75, random_state=42)\n",
    "\n",
    "modelos = [best_rnd_clf, xgb_best, best_ada_clf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d3cec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treinando classificadores com pesos para as classes\n",
    "pesos = compute_sample_weight(\"balanced\", y_train)\n",
    "treino_de_classificadores(modelos, X_train_scaled, y_train_encoded, pesos);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3750ac73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling test variables\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "y_test_encoded = encoder.transform(y_test)\n",
    "\n",
    "#testing models\n",
    "metricas_modelos = metricas_score(modelos, X_test_scaled, y_test_encoded, 'wgt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3dc140",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\")\n",
    "plt.figure(figsize = (7, 7))\n",
    "plt.ylim(0.5, 1)\n",
    "ax = sns.barplot(x=metricas_modelos['Modelo'], y=metricas_modelos['F1'], data=metricas_modelos, palette=\"pastel\")\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container)\n",
    "plt.xticks(rotation = 45)\n",
    "ax.set_yticks([0.5,0.6,0.7,0.8,0.9,1])\n",
    "ax.tick_params(axis='y', colors='black');\n",
    "plt.savefig('Scores.jpg', dpi=600, format='jpg', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23e51c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions for test\n",
    "random_forest_predictions = best_rnd_clf.predict(X_test_scaled)\n",
    "ada_boost_predictions = best_ada_clf.predict(X_test_scaled)\n",
    "\n",
    "#confusion matrix\n",
    "conf_matrix1 = confusion_matrix(y_test_encoded, random_forest_predictions)\n",
    "conf_matrix2 = confusion_matrix(y_test_encoded, ada_boost_predictions)\n",
    "\n",
    "#Displaying confusion matrix for random forest test\n",
    "fig, ax = plt.subplots(1,2,figsize=(15, 15))\n",
    "ax[0].set_title(\"Random Forest\")\n",
    "ax[1].set_title(\"ADAboost\")\n",
    "\n",
    "cm = ConfusionMatrixDisplay(conf_matrix1,display_labels=encoder.classes_)\n",
    "cm.plot(ax=ax[0], xticks_rotation=45,cmap='Blues', colorbar=False)\n",
    "\n",
    "#Displaying confusion matrix for adaboost test\n",
    "cm = ConfusionMatrixDisplay(conf_matrix2,display_labels=encoder.classes_)\n",
    "cm.plot(ax=ax[1], xticks_rotation=45,cmap='YlOrBr', colorbar=False)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.40, hspace=0.1)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1c374268",
   "metadata": {},
   "source": [
    "# <center> TRAINING AND TESTING THE BEST MODELS (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4041bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_de_classificadores(modelos, X_train_smt_scaled, y_train_smt_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dbfd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = scaler_smt.transform(X_test)\n",
    "y_test_encoded = encoder_smt.transform(y_test)\n",
    "\n",
    "#testing models\n",
    "metricas_modelos_smote = metricas_score(modelos, X_test_scaled, y_test_encoded, 'SMOTE')\n",
    "metricas_modelos_smote"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "40afe19426108136bbff523a5ee7648410555eea8397997f95af9134e9972f9a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
