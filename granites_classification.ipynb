{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c93e251",
   "metadata": {},
   "source": [
    "# <center> GRANITES CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22961b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#utilitários\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "#Pré processamento\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "\n",
    "#Modelos\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "#SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#Bayesian Optimization\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "#Avaliadores\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, \\\n",
    "    classification_report, accuracy_score, confusion_matrix, \\\n",
    "        ConfusionMatrixDisplay\n",
    "\n",
    "from sklearn.utils import compute_sample_weight\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#salvar e carregar modelos treinados\n",
    "import joblib\n",
    "\n",
    "#filtrando alertas\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "xgb.set_config(verbosity=0)\n",
    "\n",
    "#parâmetros para o matplotlib\n",
    "plt.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046ea092",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funções usadas no notebook\n",
    "\n",
    "def treino_de_classificadores(classificadores, X_treino, y_treino, pesos=None):\n",
    "    '''Função de treino de classificadores e métricas'''\n",
    "    for classificador in classificadores:\n",
    "        classificador.fit(X_treino, np.ravel(y_treino), sample_weight=pesos)\n",
    "        y_previsao = cross_val_predict(classificador, X_treino, y_treino, cv=10)\n",
    "        precisao = precision_score(y_treino, y_previsao, average = 'macro')\n",
    "        revocacao = recall_score(y_treino, y_previsao, average = 'macro')\n",
    "        pontuacao_f1 = f1_score(y_treino, y_previsao, average = 'macro')\n",
    "        print(classificador.__class__.__name__)\n",
    "        print(f'precisão:{precisao}, revocação:{revocacao}, F1 score: {pontuacao_f1}')\n",
    "        \n",
    "def teste_de_modelos(modelos, X_teste, y_teste):\n",
    "    for modelo in modelos:\n",
    "        previsoes_teste = modelo.predict(X_teste)\n",
    "        print(modelo.__class__.__name__)\n",
    "        print(classification_report(y_teste, previsoes_teste))\n",
    "        print('_________________________________________________________________________________________________________')\n",
    "        \n",
    "def metricas_score(modelos, X_teste, y_teste, imb_treatment='No_treatment'): #imb_treatment\n",
    "    '''Avialia modelos treinados com base em diferentes métricas'''\n",
    "    metricas_modelo = {}\n",
    "    for indice, modelo in enumerate(modelos):\n",
    "        nome = modelo.__class__.__name__\n",
    "        previsao = modelo.predict(X_teste)\n",
    "        f1 = f1_score(y_teste, previsao, average='macro')\n",
    "        precisao = precision_score(y_teste, previsao, average='macro')\n",
    "        acuracia = accuracy_score(y_teste, previsao)\n",
    "        imb_treatment = imb_treatment\n",
    "\n",
    "        metricas_modelo[indice] = nome, f1, acuracia, precisao, imb_treatment\n",
    "        \n",
    "        \n",
    "    return pd.DataFrame.from_dict(metricas_modelo, orient='index', columns=['Modelo', 'F1', 'Acurácia', 'Precisão', 'imb_treatment'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61a55182",
   "metadata": {},
   "source": [
    "## <center> LOADING AND PREPARING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3449f90d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Carregando o database tratado\n",
    "database = pd.read_csv('dataset/GDB_Bonin(2020)_update.csv')\n",
    "database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443120b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separando variáveis preditoras e variável alvo\n",
    "\n",
    "database_preditores = database[['SiO2', 'TiO2', 'Al2O3','FeOt', 'MnO', 'MgO', 'CaO', \n",
    "                                'K2O', 'Na2O']]\n",
    "\n",
    "database_alvo = database[['Group']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "092131e3",
   "metadata": {},
   "source": [
    "## <center> EXPLORATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6621231b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(15,15))\n",
    "plt.subplots_adjust(wspace=0.40, hspace=0.1)\n",
    "\n",
    "contagem = 0\n",
    "for i in range(0,2):\n",
    "    for j in range(0,3):\n",
    "        sns.boxplot(ax=axes[i, j], data=database_preditores, x=database_alvo['Group'], y=database_preditores.columns[contagem], palette=\"pastel\")\n",
    "        contagem += 1\n",
    "plt.setp(axes, xticks=[], xlabel=None);\n",
    "\n",
    "for i in range(2,3):\n",
    "    for j in range(0,3):\n",
    "        sns.boxplot(ax=axes[i, j], data=database_preditores, x=database_alvo['Group'], y=database_preditores.columns[contagem], palette=\"pastel\")\n",
    "        contagem += 1\n",
    "        \n",
    "for i in range(0,3):\n",
    "    axes[2,i].set_xticklabels(axes[2,i].get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "plt.setp(axes, xlabel=None);\n",
    "plt.savefig('boxplot.jpeg')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63b3890c",
   "metadata": {},
   "source": [
    "# <center> PRE PROCESSING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ce2c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizando um amostragem estratificada\n",
    "X_train, X_test, y_train, y_test = train_test_split(database_preditores, database_alvo, test_size=0.30, stratify=database_alvo, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "encoder = LabelEncoder()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "y_train_encoded = encoder.fit_transform(y_train)\n",
    "\n",
    "#Preparing SMOTE train\n",
    "#smote = SMOTE()\n",
    "#scaler_smt = StandardScaler()\n",
    "#encoder_smt = LabelEncoder()\n",
    "\n",
    "#X_train_smt, y_train_smt = smote.fit_resample(X_train, y_train)\n",
    "#X_train_smt_scaled = scaler_smt.fit_transform(X_train_smt)\n",
    "#y_train_smt_encoded = encoder_smt.fit_transform(y_train_smt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d26a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing SMOTE train\n",
    "smote = SMOTE()\n",
    "scaler_smt = StandardScaler()\n",
    "encoder_smt = LabelEncoder()\n",
    "\n",
    "X_train_smt, y_train_smt = smote.fit_resample(X_train, y_train)\n",
    "X_train_smt_scaled = scaler_smt.fit_transform(X_train_smt)\n",
    "y_train_smt_encoded = encoder_smt.fit_transform(y_train_smt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f7b58d0",
   "metadata": {},
   "source": [
    "# <center> TRAINING BASE MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363d1be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "lda_clf = LinearDiscriminantAnalysis(n_components=3)\n",
    "lda_model = lda_clf.fit(X_train_scaled, y_train_encoded).transform(X_train_scaled)\n",
    "\n",
    "models_base = [lda_clf]\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "y_test_encoded = encoder.transform(y_test)\n",
    "\n",
    "\n",
    "metricas_modelos = metricas_score(models_base, X_test_scaled, y_test_encoded, 'lda')\n",
    "metricas_modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295beb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEGENDA = encoder.classes_\n",
    "plt.subplots(figsize=(10,10))\n",
    "sns.scatterplot(x=lda_model[:,0], y=lda_model[:,1], hue=y_train_encoded, palette=\"deep\", alpha=0.7)\n",
    "plt.legend(LEGENDA, loc='upper left')\n",
    "sns.set_style(\"whitegrid\");\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b2bb415",
   "metadata": {},
   "source": [
    "# <center> TRAINING MODELS AND REALIZING HYPERPARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99552d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bayesian Optmization\n",
    "#RANDOM FOREST's\n",
    "\n",
    "def random_forest_cv(n_estimators, min_samples_split, max_features, max_depth, data, targets):\n",
    "    \"\"\"Random Forest cross validation\"\"\"\n",
    "\n",
    "    estimator = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        min_samples_split=min_samples_split,\n",
    "        max_features=max_features,\n",
    "        random_state=42,\n",
    "        max_depth=max_depth)\n",
    "    \n",
    "    cval = cross_val_score(estimator, data, targets,\n",
    "                           scoring='f1_weighted', cv=5)\n",
    "    \n",
    "    return cval.mean()\n",
    "\n",
    "def optimize_rfc(data, targets):\n",
    "    \"\"\"Apply Bayesian Optimization to Random Forest parameters.\"\"\"\n",
    "\n",
    "    def rfc_crossval(n_estimators, min_samples_split, max_features, max_depth):\n",
    "        \"\"\"Wrapper of RandomForest cross validation.\"\"\"\n",
    "\n",
    "        return random_forest_cv(\n",
    "            n_estimators=int(n_estimators),\n",
    "            min_samples_split=int(min_samples_split),\n",
    "            max_features=max(min(max_features, 0.999), 1e-3),\n",
    "            max_depth=int(max_depth),\n",
    "            data=data,\n",
    "            targets=targets)\n",
    "    \n",
    "\n",
    "    optimizer = BayesianOptimization(\n",
    "        f=rfc_crossval,\n",
    "        pbounds={\n",
    "            \"n_estimators\": (100, 200),\n",
    "            \"min_samples_split\": (2, 25),\n",
    "            \"max_features\": (0.1, 0.999),\n",
    "            \"max_depth\": (1, 10)\n",
    "        },\n",
    "        random_state=42,\n",
    "        verbose=2\n",
    "    )\n",
    "    optimizer.maximize(n_iter=100)\n",
    "\n",
    "    print(\"Final result:\", optimizer.max)\n",
    "    return optimizer.max\n",
    "\n",
    "bo = optimize_rfc(X_train_scaled, y_train_encoded)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b992cf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = bo['params']\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a90b8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(max_samples=params['max_depth'],\n",
    "                                       max_features=params['max_features'],\n",
    "                                       min_samples_split=params['min_samples_split'],\n",
    "                                       n_estimators=params['n_estimators'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f338762b",
   "metadata": {},
   "source": [
    "# <center> TRAINING AND TESTING THE BEST MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a8ef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Post GridSearCV models\n",
    "\n",
    "best_rnd_clf = RandomForestClassifier(bootstrap=False, max_features=3, criterion='entropy', n_estimators=100, random_state=42)\n",
    "xgb_best = xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=0.3,\n",
    "               colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
    "               eval_metric='mlogloss', gamma=0, gpu_id=-1, importance_type=None,\n",
    "               interaction_constraints='', learning_rate=0.2, max_delta_step=0,\n",
    "               max_depth=6, min_child_weight=1,\n",
    "               monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
    "               num_parallel_tree=5, objective='multi:softprob', predictor='auto',\n",
    "               random_state=42, reg_alpha=0, reg_lambda=1, scale_pos_weight=1.5,\n",
    "               subsample=0.9, tree_method='exact', validate_parameters=1,\n",
    "               verbosity=None)\n",
    "\n",
    "best_ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=10) ,algorithm='SAMME', n_estimators=100, learning_rate=0.75, random_state=42)\n",
    "\n",
    "modelos = [best_rnd_clf, xgb_best, best_ada_clf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d3cec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treinando classificadores com pesos para as classes\n",
    "pesos = compute_sample_weight(\"balanced\", y_train_encoded)\n",
    "treino_de_classificadores(modelos, X_train_scaled, y_train_encoded, pesos);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3750ac73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling test variables\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "y_test_encoded = encoder.transform(y_test)\n",
    "\n",
    "#testing models\n",
    "models_weight = metricas_score(modelos, X_test_scaled, y_test_encoded, 'WEIGHT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23e51c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions for test\n",
    "random_forest_predictions = best_rnd_clf.predict(X_test_scaled)\n",
    "ada_boost_predictions = best_ada_clf.predict(X_test_scaled)\n",
    "\n",
    "#confusion matrix\n",
    "conf_matrix1 = confusion_matrix(y_test_encoded, random_forest_predictions)\n",
    "conf_matrix2 = confusion_matrix(y_test_encoded, ada_boost_predictions)\n",
    "\n",
    "#Displaying confusion matrix for random forest test\n",
    "fig, ax = plt.subplots(1,2,figsize=(15, 15))\n",
    "ax[0].set_title(\"Random Forest\")\n",
    "ax[1].set_title(\"ADAboost\")\n",
    "\n",
    "cm = ConfusionMatrixDisplay(conf_matrix1,display_labels=encoder.classes_)\n",
    "cm.plot(ax=ax[0], xticks_rotation=45,cmap='Blues', colorbar=False)\n",
    "\n",
    "#Displaying confusion matrix for adaboost test\n",
    "cm = ConfusionMatrixDisplay(conf_matrix2,display_labels=encoder.classes_)\n",
    "cm.plot(ax=ax[1], xticks_rotation=45,cmap='YlOrBr', colorbar=False)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.40, hspace=0.1)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1c374268",
   "metadata": {},
   "source": [
    "# <center> TRAINING AND TESTING THE BEST MODELS (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4041bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_de_classificadores(modelos, X_train_smt_scaled, y_train_smt_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dbfd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = scaler_smt.transform(X_test)\n",
    "y_test_encoded = encoder_smt.transform(y_test)\n",
    "\n",
    "#testing models\n",
    "models_smote = metricas_score(modelos, X_test_scaled, y_test_encoded, 'SMOTE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2c7b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_modelos = pd.concat([models_weight, models_smote], axis=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf85ca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\")\n",
    "plt.figure(figsize = (7, 7))\n",
    "plt.ylim(0.5, 1)\n",
    "ax = sns.barplot(x=all_modelos['Modelo'], y=all_modelos['F1'], data=all_modelos, hue=all_modelos['imb_treatment'], palette=\"pastel\")\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container)\n",
    "plt.xticks(rotation = 45)\n",
    "ax.set_yticks([0.5,0.6,0.7,0.8,0.9,1])\n",
    "ax.tick_params(axis='y', colors='black');\n",
    "plt.savefig('Scores.jpg', dpi=600, format='jpg', bbox_inches = 'tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "40afe19426108136bbff523a5ee7648410555eea8397997f95af9134e9972f9a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
